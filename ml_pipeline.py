#!/usr/bin/env python3
"""
Pipeline ML Complet - Am√©lioration des Mod√®les d'Estimation d'Offres
====================================================================

Ce script orchestre le pipeline complet d'am√©lioration des performances :
1. G√©n√©ration de donn√©es avec Faker
2. Feature Engineering et s√©lection
3. Entra√Ænement optimis√© avec hyperparam√®tres
4. √âvaluation et validation
"""

import os
import sys
import time
from datetime import datetime

def print_header(title):
    """Affiche un en-t√™te stylis√©"""
    print("\n" + "="*60)
    print(f"üöÄ {title}")
    print("="*60)

def print_step(step, description):
    """Affiche une √©tape du pipeline"""
    print(f"\nüìã √âTAPE {step}: {description}")
    print("-" * 50)

def check_dependencies():
    """V√©rifie et installe les d√©pendances n√©cessaires"""
    print_step(0, "V√©rification des d√©pendances")
    
    required_packages = [
        'faker', 'lightgbm', 'scikit-learn', 'xgboost', 
        'pandas', 'numpy', 'matplotlib', 'seaborn'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"‚úÖ {package} - OK")
        except ImportError:
            missing_packages.append(package)
            print(f"‚ùå {package} - MANQUANT")
    
    if missing_packages:
        print(f"\n‚ö†Ô∏è Packages manquants: {', '.join(missing_packages)}")
        print("Installez-les avec: pip install " + " ".join(missing_packages))
        return False
    
    return True

def run_data_generation():
    """√âtape 1: G√©n√©ration de donn√©es avec Faker"""
    print_step(1, "G√©n√©ration de donn√©es avec Faker")
    
    try:
        from data_generator import DataGenerator
        
        print("üîÑ D√©marrage de la g√©n√©ration de donn√©es...")
        generator = DataGenerator()
        df_enhanced = generator.generate_enhanced_dataset(15000)
        
        print(f"‚úÖ Donn√©es g√©n√©r√©es: {len(df_enhanced)} soumissions")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
        return False

def run_feature_engineering():
    """√âtape 2: Feature Engineering et s√©lection"""
    print_step(2, "Feature Engineering et s√©lection")
    
    try:
        from feature_engineering import FeatureEngineer
        
        print("üîÑ D√©marrage du feature engineering...")
        engineer = FeatureEngineer()
        df_final = engineer.run_complete_feature_engineering()
        
        print(f"‚úÖ Features cr√©√©es: {len(df_final.columns)-1} features")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du feature engineering: {e}")
        return False

def run_optimized_training():
    """√âtape 3: Entra√Ænement optimis√©"""
    print_step(3, "Entra√Ænement optimis√© avec hyperparam√®tres")
    
    try:
        from optimized_training import OptimizedTrainer
        
        print("üîÑ D√©marrage de l'entra√Ænement optimis√©...")
        trainer = OptimizedTrainer()
        best_models = trainer.run_complete_optimization()
        
        print("‚úÖ Mod√®les optimis√©s cr√©√©s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
        return False

def run_validation():
    """√âtape 4: Validation des nouveaux mod√®les"""
    print_step(4, "Validation des mod√®les am√©lior√©s")
    
    try:
        # Adapter le script de validation pour les nouveaux mod√®les
        import joblib
        import pandas as pd
        from sklearn.metrics import classification_report, roc_auc_score, r2_score, mean_squared_error
        
        # Charger les nouveaux mod√®les
        clf_model = joblib.load('best_classification_model.pkl')
        reg_model = joblib.load('best_regression_model.pkl')
        scaler = joblib.load('best_scaler.pkl')
        feature_columns = joblib.load('best_feature_columns.pkl')
        
        # Charger les donn√©es de test
        df_test = pd.read_csv('final_engineered_dataset.csv')
        
        # Pr√©parer les donn√©es de test
        X_test = df_test[feature_columns]
        y_class_test = df_test['is_winner']
        y_reg_test = df_test['montant_soumis']
        
        # Normaliser
        X_test_scaled = scaler.transform(X_test)
        
        # √âvaluer classification
        y_pred_class = clf_model.predict(X_test_scaled)
        y_pred_proba = clf_model.predict_proba(X_test_scaled)[:, 1]
        
        clf_accuracy = (y_pred_class == y_class_test).mean()
        clf_auc = roc_auc_score(y_class_test, y_pred_proba)
        
        # √âvaluer r√©gression
        y_pred_reg = reg_model.predict(X_test_scaled)
        reg_r2 = r2_score(y_reg_test, y_pred_reg)
        reg_rmse = np.sqrt(mean_squared_error(y_reg_test, y_pred_reg))
        
        print("\nüìä R√âSULTATS DE VALIDATION:")
        print(f"Classification - Accuracy: {clf_accuracy:.4f}")
        print(f"Classification - ROC-AUC: {clf_auc:.4f}")
        print(f"R√©gression - R¬≤: {reg_r2:.4f}")
        print(f"R√©gression - RMSE: {reg_rmse:.2f}")
        
        # Comparer avec les anciens r√©sultats
        print("\nüìà COMPARAISON AVEC ANCIENS MOD√àLES:")
        print("Ancien - Classification ROC-AUC: 0.7457")
        print(f"Nouveau - Classification ROC-AUC: {clf_auc:.4f}")
        print(f"Am√©lioration: {(clf_auc - 0.7457)*100:.2f}%")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la validation: {e}")
        return False

def create_performance_report():
    """Cr√©e un rapport de performance complet"""
    print_step(5, "Cr√©ation du rapport de performance")
    
    try:
        report = f"""
RAPPORT DE PERFORMANCE - PIPELINE ML AM√âLIOR√â
=============================================

Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

√âTAPES EX√âCUT√âES:
‚úÖ G√©n√©ration de donn√©es avec Faker (15,000 AOs)
‚úÖ Feature Engineering avanc√©
‚úÖ S√©lection de features optimis√©e
‚úÖ Entra√Ænement avec hyperparam√®tres
‚úÖ Cr√©ation d'ensembles de mod√®les
‚úÖ Validation compl√®te

AM√âLIORATIONS APPORT√âES:
1. Donn√©es plus r√©alistes et compl√®tes
2. Features m√©tier avanc√©es
3. S√©lection de features intelligente
4. Optimisation des hyperparam√®tres
5. Ensembles de mod√®les
6. Validation robuste

FICHIERS G√âN√âR√âS:
- enhanced_ao_dataset.csv (donn√©es g√©n√©r√©es)
- final_engineered_dataset.csv (features s√©lectionn√©es)
- best_classification_model.pkl (mod√®le classification)
- best_regression_model.pkl (mod√®le r√©gression)
- best_scaler.pkl (normalisation)
- best_feature_columns.pkl (features utilis√©es)
- training_results.json (r√©sultats d√©taill√©s)

RECOMMANDATIONS:
1. Utiliser les nouveaux mod√®les en production
2. Monitorer les performances en temps r√©el
3. Retra√Æner p√©riodiquement avec de nouvelles donn√©es
4. Ajuster les seuils selon le contexte m√©tier

Pipeline ML - Projet d'Estimation d'Offres Financi√®res
Auteur: Abdelilah OURTI
"""
        
        with open('performance_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("‚úÖ Rapport sauvegard√© dans 'performance_report.txt'")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation du rapport: {e}")
        return False

def main():
    """Fonction principale du pipeline"""
    print_header("PIPELINE ML - AM√âLIORATION DES PERFORMANCES")
    
    start_time = time.time()
    
    # V√©rifier les d√©pendances
    if not check_dependencies():
        print("‚ùå D√©pendances manquantes. Arr√™t du pipeline.")
        return False
    
    # √âtape 1: G√©n√©ration de donn√©es
    if not run_data_generation():
        print("‚ùå √âchec de la g√©n√©ration de donn√©es")
        return False
    
    # √âtape 2: Feature Engineering
    if not run_feature_engineering():
        print("‚ùå √âchec du feature engineering")
        return False
    
    # √âtape 3: Entra√Ænement optimis√©
    if not run_optimized_training():
        print("‚ùå √âchec de l'entra√Ænement")
        return False
    
    # √âtape 4: Validation
    if not run_validation():
        print("‚ùå √âchec de la validation")
        return False
    
    # √âtape 5: Rapport de performance
    if not create_performance_report():
        print("‚ùå √âchec de la cr√©ation du rapport")
        return False
    
    # Calcul du temps total
    total_time = time.time() - start_time
    hours = int(total_time // 3600)
    minutes = int((total_time % 3600) // 60)
    seconds = int(total_time % 60)
    
    print_header("PIPELINE TERMIN√â AVEC SUCC√àS!")
    print(f"‚è±Ô∏è Temps total: {hours}h {minutes}m {seconds}s")
    print("\nüéâ Tous les mod√®les ont √©t√© am√©lior√©s et sont pr√™ts pour la production!")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 