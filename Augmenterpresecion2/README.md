# ğŸš€ Pipeline ML AvancÃ© pour l'Estimation d'Offres

## ğŸ“‹ Vue d'ensemble

Ce projet propose une architecture ML avancÃ©e pour prÃ©dire les rÃ©sultats d'appels d'offres avec deux objectifs principaux :
- **Classification** : PrÃ©dire si une soumission gagnera (probabilitÃ© de succÃ¨s)
- **RÃ©gression** : PrÃ©dire le montant gagnant

L'architecture a Ã©tÃ© conÃ§ue pour des serveurs avec des ressources importantes et intÃ¨gre les derniÃ¨res techniques de Machine Learning.

## ğŸ—ï¸ Architecture

### ğŸ“ Structure des fichiers

```
Augmenterpresecion2/
â”œâ”€â”€ script.py                          # GÃ©nÃ©rateur de donnÃ©es original
â”œâ”€â”€ train_models.py                    # EntraÃ®nement basique (conservÃ©)
â”œâ”€â”€ streamlit_app.py                   # Interface utilisateur amÃ©liorÃ©e
â”œâ”€â”€ requirements.txt                   # DÃ©pendances complÃ¨tes
â”œâ”€â”€ advanced_feature_engineering.py    # Feature engineering avancÃ©
â”œâ”€â”€ advanced_model_trainer.py          # EntraÃ®nement avec hyperparameter tuning
â”œâ”€â”€ model_evaluation_dashboard.py      # Dashboard d'Ã©valuation complet
â”œâ”€â”€ advanced_ml_pipeline.py           # Pipeline principal orchestrÃ©
â””â”€â”€ README.md                         # Ce fichier
```

### ğŸ”§ Modules principaux

#### 1. **Advanced Feature Engineering** (`advanced_feature_engineering.py`)
- **Features temporelles** : jour de la semaine, mois, saisonnalitÃ©
- **Features d'interaction** : produits et ratios complexes
- **Target Encoding** : encodage avancÃ© des variables catÃ©gorielles
- **Features mÃ©tier** : stratÃ©gie de prix, niveau de concurrence
- **SÃ©lection automatique** : combinaison de mÃ©thodes statistiques et ML

#### 2. **Advanced Model Trainer** (`advanced_model_trainer.py`)
- **Hyperparameter Optimization** : Optuna avec validation croisÃ©e
- **Multiples algorithmes** : XGBoost, LightGBM, CatBoost, Random Forest, SVM, MLP
- **Gestion de l'imbalance** : SMOTE pour Ã©quilibrer les classes
- **Ensembles** : VotingClassifier et VotingRegressor automatiques
- **Early stopping** : prÃ©vention de l'overfitting

#### 3. **Model Evaluation Dashboard** (`model_evaluation_dashboard.py`)
- **MÃ©triques complÃ¨tes** : ROC-AUC, Precision-Recall, RÂ², RMSE, MAE
- **Visualisations avancÃ©es** : courbes ROC, matrices de confusion, Q-Q plots
- **Dashboard interactif** : Plotly pour l'exploration
- **Analyses par segment** : performance par secteur/catÃ©gorie
- **Rapports automatiques** : recommandations et insights

#### 4. **Advanced ML Pipeline** (`advanced_ml_pipeline.py`)
- **Orchestration complÃ¨te** : 5 Ã©tapes automatisÃ©es
- **Logging avancÃ©** : suivi dÃ©taillÃ© avec timestamps
- **Gestion d'erreurs** : robustesse et rÃ©cupÃ©ration
- **Configuration flexible** : paramÃ¨tres optimisables
- **Sauvegarde automatique** : modÃ¨les et rÃ©sultats

## ğŸš€ Installation et utilisation

### 1. **Installation des dÃ©pendances**

```bash
pip install -r requirements.txt
```

### 2. **ExÃ©cution du pipeline complet**

```bash
python advanced_ml_pipeline.py
```

### 3. **Interface utilisateur**

```bash
streamlit run streamlit_app.py
```

## ğŸ“Š FonctionnalitÃ©s avancÃ©es

### ğŸ¯ **Optimisation des performances**

#### **Feature Engineering**
- **50+ features crÃ©Ã©es** automatiquement
- **SÃ©lection intelligente** des meilleures features
- **Encodage avancÃ©** des variables catÃ©gorielles
- **Features temporelles** et saisonniÃ¨res

#### **Hyperparameter Tuning**
- **Optuna** pour l'optimisation bayÃ©sienne
- **150+ essais** par modÃ¨le
- **Validation croisÃ©e** stratifiÃ©e (5-fold)
- **Early stopping** pour Ã©viter l'overfitting

#### **Ensembles de modÃ¨les**
- **VotingClassifier** pour la classification
- **VotingRegressor** pour la rÃ©gression
- **SÃ©lection automatique** des meilleurs modÃ¨les
- **PondÃ©ration optimisÃ©e** des prÃ©dictions

### ğŸ“ˆ **Ã‰valuation complÃ¨te**

#### **MÃ©triques de classification**
- **ROC-AUC** avec intervalles de confiance
- **Precision-Recall curves**
- **Matrice de confusion** avec heatmap
- **Classification report** dÃ©taillÃ©

#### **MÃ©triques de rÃ©gression**
- **RÂ², RMSE, MAE** par segment
- **Scatter plot** prÃ©dictions vs rÃ©el
- **Distribution des rÃ©sidus**
- **Q-Q plot** pour la normalitÃ©

#### **Analyses avancÃ©es**
- **Performance par secteur**
- **Analyse des erreurs**
- **StabilitÃ© temporelle**
- **DÃ©tection d'outliers**

### ğŸ¨ **Visualisations**

#### **Graphiques statiques** (Matplotlib/Seaborn)
- Layout en grille 2x3
- Couleurs cohÃ©rentes (bleus/marine)
- MÃ©triques annotÃ©es
- Export haute rÃ©solution

#### **Dashboard interactif** (Plotly)
- Graphiques interactifs
- Zoom et pan
- Hover information
- Export dynamique

## âš™ï¸ Configuration

### **Configuration par dÃ©faut optimisÃ©e**

```python
config = {
    'data_generation': {
        'n_aos': 20000,  # Nombre d'appels d'offres
        'locale': 'fr_FR'
    },
    'feature_engineering': {
        'n_features': 60,  # Features Ã  sÃ©lectionner
        'use_advanced_features': True
    },
    'model_training': {
        'n_trials': 150,  # Essais d'optimisation
        'test_size': 0.2,
        'random_state': 42
    },
    'evaluation': {
        'create_visualizations': True,
        'create_interactive_dashboard': True,
        'save_models': True
    }
}
```

### **Personnalisation**

Vous pouvez modifier la configuration dans `advanced_ml_pipeline.py` :

```python
# Configuration personnalisÃ©e
custom_config = {
    'data_generation': {'n_aos': 30000},  # Plus de donnÃ©es
    'model_training': {'n_trials': 200},   # Plus d'optimisation
    # ... autres paramÃ¨tres
}

pipeline = AdvancedMLPipeline(custom_config)
```

## ğŸ“ˆ Objectifs de performance

### **Cibles dÃ©finies**
- **Classification** : AUC-ROC > 0.85
- **RÃ©gression** : RÂ² > 0.80
- **GÃ©nÃ©ralisation** : Gap train/val < 5%
- **StabilitÃ©** : Validation croisÃ©e stable

### **MÃ©triques business**
- **PrÃ©cision des prÃ©dictions** de gain
- **Estimation prÃ©cise** des montants
- **ROI des recommandations**
- **RÃ©duction des coÃ»ts** d'opportunitÃ©

## ğŸ” Monitoring et logging

### **Logs dÃ©taillÃ©s**
- **Timestamps** pour chaque Ã©tape
- **MÃ©triques de performance** en temps rÃ©el
- **Gestion d'erreurs** avec stack traces
- **Sauvegarde automatique** des logs

### **Fichiers gÃ©nÃ©rÃ©s**
```
logs/
â”œâ”€â”€ advanced_pipeline_20241201_143022.log
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ classification_xgboost.pkl
â”‚   â”œâ”€â”€ classification_lightgbm.pkl
â”‚   â”œâ”€â”€ regression_xgboost.pkl
â”‚   â””â”€â”€ metadata.pkl
â”œâ”€â”€ classification_evaluation.png
â”œâ”€â”€ regression_evaluation.png
â””â”€â”€ pipeline_results.json
```

## ğŸ› ï¸ Utilisation avancÃ©e

### **EntraÃ®nement personnalisÃ©**

```python
from advanced_model_trainer import AdvancedModelTrainer

# CrÃ©er un trainer personnalisÃ©
trainer = AdvancedModelTrainer(random_state=42)

# PrÃ©parer les donnÃ©es
X_train, X_test, y_train, y_test, features = trainer.prepare_data(df)

# EntraÃ®ner avec optimisation
results = trainer.train_models(X_train, y_train, X_test, y_test, task='classification')

# CrÃ©er un ensemble
ensemble, score = trainer.create_ensemble(X_train, y_train, X_test, y_test, task='classification')
```

### **Ã‰valuation personnalisÃ©e**

```python
from model_evaluation_dashboard import ModelEvaluationDashboard

# CrÃ©er le dashboard
dashboard = ModelEvaluationDashboard(models_data, X_test, y_test)

# Ã‰valuation complÃ¨te
report = dashboard.run_complete_evaluation()

# Analyse par segment
segment_analysis = dashboard.analyze_performance_by_segment('secteur')
```

### **Feature Engineering personnalisÃ©**

```python
from advanced_feature_engineering import AdvancedFeatureEngineer

# CrÃ©er l'engineer
engineer = AdvancedFeatureEngineer()

# Engineering complet
df_engineered, selected_features = engineer.run_complete_engineering(df)

# Ou Ã©tapes individuelles
df = engineer.extract_numeric_features(df)
df = engineer.create_temporal_features(df)
df = engineer.create_interaction_features(df)
```

## ğŸš¨ DÃ©pannage

### **ProblÃ¨mes courants**

#### **1. Erreur d'import**
```bash
# Solution : installer les dÃ©pendances manquantes
pip install category_encoders optuna
```

#### **2. MÃ©moire insuffisante**
```python
# RÃ©duire la configuration
config['data_generation']['n_aos'] = 10000
config['model_training']['n_trials'] = 50
```

#### **3. ModÃ¨les non trouvÃ©s**
```bash
# ExÃ©cuter d'abord le pipeline
python advanced_ml_pipeline.py
```

### **Optimisation des performances**

#### **Pour serveurs puissants**
```python
config = {
    'data_generation': {'n_aos': 50000},
    'feature_engineering': {'n_features': 100},
    'model_training': {'n_trials': 300}
}
```

#### **Pour serveurs limitÃ©s**
```python
config = {
    'data_generation': {'n_aos': 5000},
    'feature_engineering': {'n_features': 30},
    'model_training': {'n_trials': 50}
}
```

## ğŸ“š Ressources additionnelles

### **Documentation technique**
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Category Encoders](https://contrib.scikit-learn.org/category_encoders/)

### **Bonnes pratiques ML**
- Validation croisÃ©e stratifiÃ©e
- Gestion de l'imbalance des classes
- Feature selection automatique
- Monitoring de la dÃ©rive

## ğŸ¤ Contribution

Pour contribuer au projet :

1. **Fork** le repository
2. **CrÃ©er** une branche feature
3. **ImplÃ©menter** les amÃ©liorations
4. **Tester** avec le pipeline complet
5. **Soumettre** une pull request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

---

**ğŸ¯ Objectif** : CrÃ©er le meilleur systÃ¨me de prÃ©diction d'appels d'offres avec des performances optimales et une interprÃ©tabilitÃ© maximale. 