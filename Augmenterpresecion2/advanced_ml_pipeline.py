"""
Pipeline ML Avanc√© pour les Appels d'Offres
Int√®gre : feature engineering, hyperparameter tuning, ensembles, √©valuation compl√®te
"""

import pandas as pd
import numpy as np
import time
import logging
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Import des modules personnalis√©s
from script import AppelOffreGenerator
from advanced_feature_engineering import AdvancedFeatureEngineer
from advanced_model_trainer import AdvancedModelTrainer
from model_evaluation_dashboard import ModelEvaluationDashboard

class AdvancedMLPipeline:
    """Pipeline ML avanc√© complet"""
    
    def __init__(self, config=None):
        self.config = config or self.get_default_config()
        self.setup_logging()
        self.results = {}
        
    def get_default_config(self):
        """Configuration par d√©faut optimis√©e"""
        return {
            'data_generation': {
                'n_aos': 20000,  # Nombre d'appels d'offres
                'locale': 'fr_FR'
            },
            'feature_engineering': {
                'n_features': 50,  # Nombre de features √† s√©lectionner
                'use_advanced_features': True
            },
            'model_training': {
                'n_trials': 100,  # Nombre d'essais pour l'optimisation
                'test_size': 0.2,
                'random_state': 42
            },
            'evaluation': {
                'create_visualizations': True,
                'create_interactive_dashboard': True,
                'save_models': True
            }
        }
    
    def setup_logging(self):
        """Configure le syst√®me de logging"""
        log_dir = 'logs'
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = f'{log_dir}/advanced_pipeline_{timestamp}.log'
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("Pipeline ML avance initialise")
    
    def step_1_generate_data(self):
        """√âtape 1: G√©n√©ration de donn√©es"""
        self.logger.info("=" * 60)
        self.logger.info("ETAPE 1: GENERATION DE DONNEES")
        self.logger.info("=" * 60)
        
        start_time = time.time()
        
        try:
            # G√©n√©rer les donn√©es
            generator = AppelOffreGenerator()
            df_json, df_csv = generator.generer_dataset(
                self.config['data_generation']['n_aos']
            )
            
            # Cr√©er le dataset de soumissions
            df = pd.DataFrame(df_csv)
            
            # Pr√©parer les donn√©es pour l'analyse
            df = self.prepare_submission_dataset(df)
            
            elapsed_time = time.time() - start_time
            
            self.results['data_generation'] = {
                'status': 'success',
                'n_samples': len(df),
                'n_features': len(df.columns),
                'elapsed_time': elapsed_time
            }
            
            self.logger.info(f"Donnees generees: {len(df)} echantillons en {elapsed_time:.2f}s")
            return df
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la generation de donnees: {e}")
            raise
    
    def prepare_submission_dataset(self, df):
        """Pr√©pare le dataset au niveau soumission"""
        print("üîß Pr√©paration du dataset de soumissions...")
        
        # Cr√©er des soumissions √† partir des appels d'offres
        submissions = []
        
        for _, ao in df.iterrows():
            # Extraire les soumissionnaires et montants
            soumissionnaires = ao['soumissionnaires'].split('; ') if isinstance(ao['soumissionnaires'], str) else []
            montants = ao['montants_soumis'].split('; ') if isinstance(ao['montants_soumis'], str) else []
            
            # Cr√©er une soumission pour chaque soumissionnaire
            for i, soumissionnaire in enumerate(soumissionnaires):
                if i < len(montants):
                    montant = float(montants[i].replace(' DH', '').replace(',', '')) if montants[i] else 0
                else:
                    montant = 0
                
                # D√©terminer si c'est le gagnant
                is_winner = 1 if soumissionnaire == ao['soumissionnaire_gagnant'] else 0
                
                submission = {
                    'id_appel_offre': ao['id_appel_offre'],
                    'soumissionnaire': soumissionnaire,
                    'montant_soumis': montant,
                    'is_winner': is_winner,
                    'budget_estime': ao['budget_estime'],
                    'montant_gagnant': ao['montant_gagnant'],
                    'montant_moyen': ao['montant_moyen'],
                    'nombre_soumissionnaires': ao['nombre_soumissionnaires'],
                    'experience_gagnant': ao['experience_gagnant'],
                    'notation_technique_gagnant': ao['notation_technique_gagnant'],
                    'delai_execution': ao['delai_execution'],
                    'secteur': ao['secteur'],
                    'type_procedure': ao['type_procedure'],
                    'critere_attribution': ao['critere_attribution'],
                    'complexite_projet': ao['complexite_projet'],
                    'statut_ao': ao['statut_ao'],
                    'date_publication': ao['date_publication'],
                    'date_limite': ao['date_limite'],
                    'date_resultat': ao['date_resultat'],
                    'ville': ao['ville'],
                    'organisme_emetteur': ao['organisme_emetteur']
                }
                submissions.append(submission)
        
        df_submissions = pd.DataFrame(submissions)
        print(f"‚úÖ {len(df_submissions)} soumissions cr√©√©es")
        
        return df_submissions
    
    def step_2_feature_engineering(self, df):
        """√âtape 2: Feature Engineering avanc√©"""
        self.logger.info("=" * 60)
        self.logger.info("ETAPE 2: FEATURE ENGINEERING AVANCE")
        self.logger.info("=" * 60)
        
        start_time = time.time()
        
        try:
            # Initialiser le feature engineer
            feature_engineer = AdvancedFeatureEngineer()
            
            # Appliquer l'ing√©nierie de features
            df_engineered, selected_features = feature_engineer.run_complete_engineering(
                df, target_col='is_winner'
            )
            
            elapsed_time = time.time() - start_time
            
            self.results['feature_engineering'] = {
                'status': 'success',
                'n_features': len(selected_features),
                'selected_features': selected_features,
                'elapsed_time': elapsed_time
            }
            
            self.logger.info(f"Features creees: {len(selected_features)} features en {elapsed_time:.2f}s")
            return df_engineered, selected_features
            
        except Exception as e:
            self.logger.error(f"Erreur lors du feature engineering: {e}")
            raise
    
    def step_3_model_training(self, df_engineered, selected_features):
        """√âtape 3: Entra√Ænement des mod√®les"""
        self.logger.info("=" * 60)
        self.logger.info("ETAPE 3: ENTRAINEMENT DES MODELES")
        self.logger.info("=" * 60)
        
        start_time = time.time()
        
        try:
            # Initialiser le trainer
            trainer = AdvancedModelTrainer(random_state=self.config['model_training']['random_state'])
            
            # Pr√©parer les donn√©es
            X_train, X_test, y_train, y_test, feature_cols = trainer.prepare_data(
                df_engineered, 
                target_col='is_winner',
                test_size=self.config['model_training']['test_size']
            )
            
            # Entra√Æner les mod√®les de classification
            classification_results = trainer.train_models(
                X_train, y_train, X_test, y_test, task='classification'
            )
            
            # Cr√©er un ensemble
            ensemble, ensemble_score = trainer.create_ensemble(
                X_train, y_train, X_test, y_test, task='classification'
            )
            
            # √âvaluer les mod√®les
            evaluation_results = trainer.evaluate_models(X_test, y_test, task='classification')
            
            # Sauvegarder les mod√®les
            if self.config['evaluation']['save_models']:
                trainer.save_models()
            
            elapsed_time = time.time() - start_time
            
            self.results['model_training'] = {
                'status': 'success',
                'classification_results': classification_results,
                'ensemble_score': ensemble_score,
                'evaluation_results': evaluation_results,
                'elapsed_time': elapsed_time
            }
            
            self.logger.info(f"Entrainement termine en {elapsed_time:.2f}s")
            return trainer, evaluation_results
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'entrainement: {e}")
            raise
    
    def step_4_evaluation(self, training_results):
        """√âtape 4: √âvaluation compl√®te"""
        self.logger.info("=" * 60)
        self.logger.info("ETAPE 4: EVALUATION COMPLETE")
        self.logger.info("=" * 60)
        
        start_time = time.time()
        
        try:
            # Cr√©er le dashboard d'√©valuation
            dashboard = ModelEvaluationDashboard(
                models_data=training_results,
                X_test=None,  # Sera d√©fini plus tard
                y_test=None    # Sera d√©fini plus tard
            )
            
            # G√©n√©rer les rapports
            evaluation_report = dashboard.generate_comprehensive_report()
            
            # Cr√©er les visualisations
            if self.config['evaluation']['create_visualizations']:
                dashboard.create_all_visualizations()
            
            elapsed_time = time.time() - start_time
            
            self.results['evaluation'] = {
                'status': 'success',
                'evaluation_report': evaluation_report,
                'elapsed_time': elapsed_time
            }
            
            self.logger.info(f"Evaluation terminee en {elapsed_time:.2f}s")
            return evaluation_report
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'evaluation: {e}")
            raise
    
    def step_5_save_results(self, training_results):
        """√âtape 5: Sauvegarde des r√©sultats"""
        self.logger.info("=" * 60)
        self.logger.info("ETAPE 5: SAUVEGARDE DES RESULTATS")
        self.logger.info("=" * 60)
        
        try:
            # Cr√©er le dossier de r√©sultats
            results_dir = 'results'
            if not os.path.exists(results_dir):
                os.makedirs(results_dir)
            
            # Sauvegarder les r√©sultats en JSON
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            results_file = f'{results_dir}/pipeline_results_{timestamp}.json'
            
            # Convertir les r√©sultats en format JSON-serializable
            json_results = {}
            for key, value in self.results.items():
                if isinstance(value, dict):
                    json_results[key] = {k: str(v) if not isinstance(v, (int, float, str, bool)) else v 
                                       for k, v in value.items()}
                else:
                    json_results[key] = str(value)
            
            import json
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(json_results, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"Resultats sauvegardes: {results_file}")
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la sauvegarde: {e}")
            raise
    
    def run_complete_pipeline(self):
        """Ex√©cute le pipeline complet"""
        self.logger.info("DEMARRAGE DU PIPELINE ML AVANCE COMPLET")
        self.logger.info("=" * 80)
        
        total_start_time = time.time()
        
        try:
            # √âtape 1: G√©n√©ration de donn√©es
            df = self.step_1_generate_data()
            
            # √âtape 2: Feature Engineering
            df_engineered, selected_features = self.step_2_feature_engineering(df)
            
            # √âtape 3: Entra√Ænement des mod√®les
            trainer, evaluation_results = self.step_3_model_training(df_engineered, selected_features)
            
            # √âtape 4: √âvaluation
            evaluation_report = self.step_4_evaluation(evaluation_results)
            
            # √âtape 5: Sauvegarde
            self.step_5_save_results(evaluation_results)
            
            # R√©sum√© final
            total_time = time.time() - total_start_time
            self.display_summary(evaluation_report)
            
            self.logger.info("=" * 80)
            self.logger.info(f"PIPELINE TERMINE AVEC SUCCES - Temps total: {total_time:.2f}s")
            self.logger.info("=" * 80)
            
            return True
            
        except Exception as e:
            total_time = time.time() - total_start_time
            self.logger.error(f"ERREUR CRITIQUE DANS LE PIPELINE: {e}")
            self.logger.error(f"Temps ecoule: {total_time:.2f} secondes")
            self.logger.error("")
            self.logger.error("üéØ R√©sultat final: √âCHEC")
            self.logger.error(f"‚è±Ô∏è Temps total: {total_time:.2f} secondes")
            return False
    
    def display_summary(self, evaluation_report):
        """Affiche un r√©sum√© des r√©sultats"""
        print("\n" + "=" * 80)
        print("üìä R√âSUM√â DES PERFORMANCES")
        print("=" * 80)
        
        if 'classification_results' in self.results.get('model_training', {}):
            results = self.results['model_training']['classification_results']
            
            print("\nüèÜ TOP 3 MOD√àLES DE CLASSIFICATION:")
            sorted_models = sorted(results.items(), key=lambda x: x[1]['test_score'], reverse=True)
            
            for i, (name, result) in enumerate(sorted_models[:3], 1):
                print(f"  {i}. {name.upper()}: {result['test_score']:.4f}")
        
        if 'ensemble_score' in self.results.get('model_training', {}):
            ensemble_score = self.results['model_training']['ensemble_score']
            print(f"\nü§ù ENSEMBLE: {ensemble_score:.4f}")
        
        print("\n‚úÖ Pipeline ex√©cut√© avec succ√®s!")
        print("üìÅ R√©sultats sauvegard√©s dans le dossier 'results/'")
        print("üéØ Mod√®les sauvegard√©s dans le dossier 'models/'")

def main():
    """Fonction principale"""
    # Cr√©er et ex√©cuter le pipeline
    pipeline = AdvancedMLPipeline()
    success = pipeline.run_complete_pipeline()
    
    if success:
        print("\nüéâ Pipeline termin√© avec succ√®s!")
    else:
        print("\n‚ùå Pipeline √©chou√©!")

if __name__ == "__main__":
    main() 